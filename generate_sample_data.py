"""
generate_sample_data.py â€” Gerador de Dados SintÃ©ticos DeterminÃ­sticos
======================================================================

OBJETIVO:
    Gerar duas bases de dados sintÃ©ticas que simulam uma operadora de
    benefÃ­cios corporativos (tipo Pluxee, Sodexo, Alelo). Essas bases
    alimentam as 4 anÃ¡lises do portfÃ³lio Deep Dive Analyses.

POR QUE DADOS SINTÃ‰TICOS?
    Em portfÃ³lio pÃºblico, nÃ£o Ã© possÃ­vel usar dados reais de empresas.
    Dados sintÃ©ticos determinÃ­sticos (seed=42) garantem:
    - Reprodutibilidade: qualquer pessoa gera exatamente os mesmos dados
    - Realismo: distribuiÃ§Ãµes, sazonalidade e proporÃ§Ãµes simulam cenÃ¡rios reais
    - SeguranÃ§a: nenhum dado confidencial Ã© exposto

BASES GERADAS:
    1. base_vendas_historica.csv (em data/)
       â†’ Tabela de fatos: uma linha por transaÃ§Ã£o de faturamento
       â†’ Colunas: data, mes_ref, cliente_id, produto, canal, regional,
         quantidade, receita, custo, desconto_pct

    2. forecast_mensal.csv (em data/)
       â†’ Tabela de meta/forecast por canal Ã— regional Ã— produto Ã— mÃªs
       â†’ Colunas: mes_ref, canal, regional, produto, meta_receita,
         forecast_receita

CONTEXTO DE NEGÃ“CIO SIMULADO:
    Empresa: operadora de benefÃ­cios corporativos
    Produtos recorrentes: Vale AlimentaÃ§Ã£o, Vale RefeiÃ§Ã£o, Vale CombustÃ­vel
    Produtos complementares: Vale Transporte, Home Office, Gift,
                             Vale Cultura, Vale SaÃºde, Vale Mobilidade
    Canais: PME, Corporativo, Grandes Contas, Setor PÃºblico
    RegiÃµes: Norte, Nordeste, Centro-Oeste, Sudeste, Sul

COMO EXECUTAR:
    python generate_sample_data.py

COMO REAPROVEITAR:
    Altere DataGenConfig para ajustar perÃ­odo, volume e seed.
    Altere as listas de produtos/canais para simular outro negÃ³cio.

DEPENDÃŠNCIAS:
    pip install pandas numpy
"""

from __future__ import annotations

from dataclasses import dataclass
from datetime import datetime
from pathlib import Path

import numpy as np
import pandas as pd


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURAÃ‡ÃƒO
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass(frozen=True)
class DataGenConfig:
    """
    ParÃ¢metros de geraÃ§Ã£o dos dados sintÃ©ticos.

    Altere aqui para ajustar o volume e o perÃ­odo dos dados.
    O seed garante reprodutibilidade: mesmo seed = mesmos dados.
    """
    seed: int = 42
    start_date: str = "2021-01-01"
    end_date: str = "2026-01-31"
    n_rows: int = 120_000        # Total de transaÃ§Ãµes
    n_clients: int = 5_000       # Base de clientes Ãºnicos


REPO_ROOT = Path(__file__).resolve().parent
DATA_DIR = REPO_ROOT / "data"

# â”€â”€ Produtos â”€â”€
# Recorrentes: sÃ£o a base do faturamento (maior frequÃªncia)
# Complementares: geram receita adicional (menor frequÃªncia)
PRODUTOS = np.array([
    "Vale AlimentaÃ§Ã£o",    # Recorrente â€” maior volume
    "Vale RefeiÃ§Ã£o",       # Recorrente
    "Vale CombustÃ­vel",    # Recorrente
    "Vale Transporte",     # Complementar
    "Home Office",         # Complementar
    "Gift",                # Complementar
    "Vale Cultura",        # Complementar
    "Vale SaÃºde",          # Complementar
    "Vale Mobilidade",     # Complementar
])

# Probabilidade de cada produto ser comprado (simula mix real)
# Recorrentes tÃªm probabilidade maior
PRODUTO_PROBS = np.array([
    0.22,   # Vale AlimentaÃ§Ã£o â€” carro-chefe
    0.20,   # Vale RefeiÃ§Ã£o â€” segundo maior
    0.15,   # Vale CombustÃ­vel
    0.10,   # Vale Transporte
    0.08,   # Home Office
    0.07,   # Gift
    0.07,   # Vale Cultura
    0.06,   # Vale SaÃºde
    0.05,   # Vale Mobilidade
])

# â”€â”€ Canais de venda â”€â”€
CANAIS = np.array(["PME", "Corporativo", "Grandes Contas", "Setor PÃºblico"])
CANAL_PROBS = np.array([0.40, 0.30, 0.18, 0.12])

# â”€â”€ RegiÃµes â”€â”€
REGIONAIS = np.array(["Norte", "Nordeste", "Centro-Oeste", "Sudeste", "Sul"])
REGIONAL_PROBS = np.array([0.08, 0.18, 0.10, 0.42, 0.22])

# â”€â”€ PreÃ§o base por produto (R$ por unidade/mÃªs) â”€â”€
# Simula o valor mÃ©dio que uma empresa paga por funcionÃ¡rio/mÃªs
PRECO_BASE = {
    "Vale AlimentaÃ§Ã£o":  620,
    "Vale RefeiÃ§Ã£o":     580,
    "Vale CombustÃ­vel":  450,
    "Vale Transporte":   320,
    "Home Office":       280,
    "Gift":              200,
    "Vale Cultura":      150,
    "Vale SaÃºde":        380,
    "Vale Mobilidade":   250,
}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# VALIDAÃ‡Ã•ES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _validate_sales_schema(df: pd.DataFrame) -> None:
    """
    Valida o schema da base de vendas antes de salvar.

    Verifica:
    - Todas as colunas esperadas existem
    - NÃ£o hÃ¡ nulos
    - NÃ£o hÃ¡ duplicatas
    - Desconto estÃ¡ entre 0% e 25%
    - Valores numÃ©ricos sÃ£o positivos
    """
    expected = {
        "data", "mes_ref", "cliente_id", "produto", "canal",
        "regional", "quantidade", "receita", "custo", "desconto_pct",
    }
    missing = expected - set(df.columns)
    if missing:
        raise ValueError(f"Schema incompleto em vendas: {sorted(missing)}")

    if df.isna().sum().sum() > 0:
        raise ValueError("HÃ¡ nulos na base de vendas.")

    dup = df.duplicated().sum()
    if dup > 0:
        raise ValueError(f"HÃ¡ {dup} linhas duplicadas na base de vendas.")

    if not df["desconto_pct"].between(0, 0.25).all():
        raise ValueError("desconto_pct fora do range [0, 0.25].")

    if (df[["quantidade", "receita", "custo"]] <= 0).any().any():
        raise ValueError("quantidade/receita/custo devem ser positivos.")


def _validate_forecast_schema(df: pd.DataFrame) -> None:
    """
    Valida o schema da base de forecast antes de salvar.

    Verifica:
    - Todas as colunas esperadas existem
    - NÃ£o hÃ¡ nulos
    - NÃ£o hÃ¡ duplicatas na chave composta
    """
    expected = {
        "mes_ref", "canal", "regional", "produto",
        "meta_receita", "forecast_receita",
    }
    missing = expected - set(df.columns)
    if missing:
        raise ValueError(f"Schema incompleto em forecast: {sorted(missing)}")

    if df.isna().sum().sum() > 0:
        raise ValueError("HÃ¡ nulos na base de forecast.")

    if df.duplicated(["mes_ref", "canal", "regional", "produto"]).sum() > 0:
        raise ValueError("HÃ¡ duplicidades na chave mes_ref/canal/regional/produto.")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# GERAÃ‡ÃƒO DOS DADOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_sample_data(config: DataGenConfig) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    Gera dados sintÃ©ticos determinÃ­sticos para vendas e forecast.

    EXPLICAÃ‡ÃƒO PARA LEIGOS:
        Esta funÃ§Ã£o cria dados "falsos mas realistas" que imitam
        o comportamento de uma operadora de benefÃ­cios corporativos:
        - Sazonalidade: janeiro tem reajuste anual (+3%)
        - Mix de produtos: Vale AlimentaÃ§Ã£o Ã© o carro-chefe
        - ConcentraÃ§Ã£o: Sudeste tem 42% do volume (simula Brasil real)
        - Desconto: varia de 0% a 25% (polÃ­tica comercial tÃ­pica)
        - Forecast: meta = realizado Ã— fator aleatÃ³rio (0.95 a 1.08)

    ParÃ¢metros:
        config: DataGenConfig com seed, perÃ­odo, volume

    Retorna:
        (sales, forecast): tuple de DataFrames
    """
    rng = np.random.default_rng(config.seed)
    dates = pd.date_range(config.start_date, config.end_date, freq="D")

    # â”€â”€ Gerar transaÃ§Ãµes â”€â”€
    sampled_dates = rng.choice(dates, size=config.n_rows, replace=True)
    cliente_id = rng.integers(10_000, 10_000 + config.n_clients, size=config.n_rows)
    produto = rng.choice(PRODUTOS, size=config.n_rows, p=PRODUTO_PROBS)
    canal = rng.choice(CANAIS, size=config.n_rows, p=CANAL_PROBS)
    regional = rng.choice(REGIONAIS, size=config.n_rows, p=REGIONAL_PROBS)

    # â”€â”€ Quantidade: funcionÃ¡rios atendidos por transaÃ§Ã£o â”€â”€
    # PME: 1-10, Corporativo: 5-30, Grandes Contas: 20-80, Setor PÃºblico: 10-50
    quantidade = np.where(
        canal == "PME", rng.integers(1, 11, size=config.n_rows),
        np.where(
            canal == "Corporativo", rng.integers(5, 31, size=config.n_rows),
            np.where(
                canal == "Grandes Contas", rng.integers(20, 81, size=config.n_rows),
                rng.integers(10, 51, size=config.n_rows),  # Setor PÃºblico
            )
        )
    )

    # â”€â”€ PreÃ§o base por produto â”€â”€
    preco_base = pd.Series(produto).map(PRECO_BASE).to_numpy(dtype=float)

    # â”€â”€ Sazonalidade mensal â”€â”€
    # Janeiro: +3% (reajuste anual)
    # Novembro-Dezembro: +2% (efeito fim de ano / gift)
    # Fevereiro: -1% (mÃªs curto)
    mes = pd.DatetimeIndex(sampled_dates).month.to_numpy()
    sazonal = np.ones(config.n_rows)
    sazonal[mes == 1] = 1.03    # Reajuste anual
    sazonal[mes == 2] = 0.99    # MÃªs curto
    sazonal[mes == 11] = 1.02   # Fim de ano
    sazonal[mes == 12] = 1.02   # Fim de ano

    # â”€â”€ Desconto (0% a 25%) â”€â”€
    # Grandes Contas e Setor PÃºblico tendem a negociar mais desconto
    desconto_base = rng.uniform(0, 0.15, size=config.n_rows)
    desconto_extra = np.where(
        (canal == "Grandes Contas") | (canal == "Setor PÃºblico"),
        rng.uniform(0, 0.10, size=config.n_rows),
        0,
    )
    desconto_pct = np.clip(desconto_base + desconto_extra, 0, 0.25).round(4)

    # â”€â”€ Receita = quantidade Ã— preÃ§o Ã— sazonalidade Ã— (1 - desconto) Ã— ruÃ­do â”€â”€
    ruido = rng.normal(1.0, 0.08, size=config.n_rows)
    receita = (quantidade * preco_base * sazonal * (1 - desconto_pct) * ruido).clip(min=30)

    # â”€â”€ Custo = receita Ã— fator de custo (55% a 82%) â”€â”€
    custo = (receita * rng.uniform(0.55, 0.82, size=config.n_rows)).clip(min=10)

    # â”€â”€ Montar DataFrame de vendas â”€â”€
    sales = pd.DataFrame({
        "data": pd.to_datetime(sampled_dates),
        "cliente_id": cliente_id,
        "produto": produto,
        "canal": canal,
        "regional": regional,
        "quantidade": quantidade,
        "receita": receita.round(2),
        "custo": custo.round(2),
        "desconto_pct": desconto_pct,
    }).sort_values("data", ignore_index=True)

    sales["mes_ref"] = sales["data"].dt.to_period("M").astype(str)
    sales = sales[[
        "data", "mes_ref", "cliente_id", "produto", "canal",
        "regional", "quantidade", "receita", "custo", "desconto_pct",
    ]]

    # â”€â”€ Gerar forecast (meta e forecast por dimensÃ£o Ã— mÃªs) â”€â”€
    # Meta = realizado Ã— fator aleatÃ³rio (0.95 a 1.08)
    # Simula meta definida pela Ã¡rea comercial com variaÃ§Ã£o de Â±5-8%
    monthly = (
        sales.groupby(["mes_ref", "canal", "regional", "produto"], as_index=False)["receita"]
        .sum()
        .rename(columns={"receita": "realizado"})
    )
    monthly["meta_receita"] = (
        monthly["realizado"] * rng.uniform(0.95, 1.08, size=len(monthly))
    ).round(2)
    monthly["forecast_receita"] = (
        monthly["meta_receita"] * rng.uniform(0.96, 1.04, size=len(monthly))
    ).round(2)

    forecast = monthly[[
        "mes_ref", "canal", "regional", "produto",
        "meta_receita", "forecast_receita",
    ]].copy()

    # â”€â”€ Validar antes de retornar â”€â”€
    _validate_sales_schema(sales)
    _validate_forecast_schema(forecast)

    return sales, forecast


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXECUÃ‡ÃƒO PRINCIPAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main() -> None:
    """
    Gera as bases de dados e salva em data/.

    Execute este script UMA VEZ antes de rodar qualquer anÃ¡lise.
    As 4 anÃ¡lises leem os CSVs gerados aqui.
    """
    print("\n" + "ğŸ“Š" * 30)
    print("  GERADOR DE DADOS SINTÃ‰TICOS â€” DEEP DIVE ANALYSES")
    print("ğŸ“Š" * 30)

    config = DataGenConfig()
    DATA_DIR.mkdir(parents=True, exist_ok=True)

    print(f"\nâš™ï¸ ConfiguraÃ§Ã£o:")
    print(f"   Seed: {config.seed}")
    print(f"   PerÃ­odo: {config.start_date} a {config.end_date}")
    print(f"   TransaÃ§Ãµes: {config.n_rows:,}")
    print(f"   Clientes: {config.n_clients:,}")

    print("\nğŸ”„ Gerando dados...")
    sales, forecast = generate_sample_data(config)

    sales_path = DATA_DIR / "base_vendas_historica.csv"
    forecast_path = DATA_DIR / "forecast_mensal.csv"

    sales.to_csv(sales_path, index=False, encoding="utf-8")
    forecast.to_csv(forecast_path, index=False, encoding="utf-8")

    # â”€â”€ Resumo dos dados gerados â”€â”€
    print("\nâœ… Dados gerados com sucesso!")
    print(f"\nğŸ“ Base de vendas: {sales_path}")
    print(f"   Linhas: {len(sales):,}")
    print(f"   Clientes Ãºnicos: {sales['cliente_id'].nunique():,}")
    print(f"   Produtos: {sales['produto'].nunique()}")
    print(f"   Canais: {', '.join(sales['canal'].unique())}")
    print(f"   PerÃ­odo: {sales['mes_ref'].min()} a {sales['mes_ref'].max()}")
    print(f"   Receita total: R$ {sales['receita'].sum():,.2f}")

    print(f"\nğŸ“ Base de forecast: {forecast_path}")
    print(f"   Linhas: {len(forecast):,}")
    print(f"   Meta total: R$ {forecast['meta_receita'].sum():,.2f}")

    print("\n" + "=" * 60)
    print("PrÃ³ximo passo: execute cada anÃ¡lise individualmente:")
    print("   python 01_analise_safra/scripts/analise_safra.py")
    print("   python 02_analise_pareto_abc/scripts/analise_pareto.py")
    print("   python 03_analise_ad_hoc/scripts/analise_adhoc.py")
    print("   python 04_indicadores_vendas_mensal/scripts/analise_indicadores.py")
    print("=" * 60)


if __name__ == "__main__":
    main()
