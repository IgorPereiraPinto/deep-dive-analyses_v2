"""
analise_safra.py â€” AnÃ¡lise de Safra (Cohort / Coorte)
=====================================================

OBJETIVO:
    Avaliar a retenÃ§Ã£o de clientes agrupados pela safra (mÃªs da primeira compra).
    A anÃ¡lise responde: "dos clientes que entraram em um determinado mÃªs,
    quantos ainda estavam comprando 1, 2, 3... meses depois?"

PERGUNTA DE NEGÃ“CIO:
    "Quais coortes retÃªm melhor nos meses M1, M2 e M3?
     Onde hÃ¡ queda acelerada de retenÃ§Ã£o?"

COMO EXECUTAR:
    python 01_analise_safra/scripts/analise_safra.py

OUTPUTS GERADOS (em 01_analise_safra/outputs/):
    - 01_resumo_executivo.txt  â†’ leitura rÃ¡pida para gestores (2 min)
    - 02_tabela_resultados.xlsx â†’ abas resumo / detalhe / parametros
    - 03_grafico_principal.png  â†’ heatmap de retenÃ§Ã£o por coorte

COMO REAPROVEITAR COM SEUS PRÃ“PRIOS DADOS:
    Se vocÃª quer usar este script com dados reais, altere apenas estas variÃ¡veis:

    1. CAMINHO DOS DADOS (linha ~80):
       Troque: REPO_ROOT / "data/base_vendas_historica.csv"
       Por:    o caminho do seu arquivo (CSV ou Excel)

    2. NOMES DAS COLUNAS (linha ~85):
       O script espera 3 colunas mÃ­nimas:
       - "cliente_id"  â†’ identificador Ãºnico do cliente
       - "data"        â†’ data da transaÃ§Ã£o (formato YYYY-MM-DD)
       - "receita"     â†’ valor faturado na transaÃ§Ã£o (> 0)
       Se suas colunas tÃªm nomes diferentes, renomeie no pd.read_csv()
       usando o parÃ¢metro: .rename(columns={"seu_nome": "cliente_id"})

    3. PASTA DE SAÃDA (linha ~75):
       Troque OUTPUT_DIR se quiser salvar em outro local.

    O restante do cÃ³digo Ã© genÃ©rico e funciona para qualquer base
    que tenha essas 3 colunas.

DEPENDÃŠNCIAS:
    pip install pandas matplotlib openpyxl
"""

from __future__ import annotations

from datetime import datetime
from pathlib import Path
import sys

import matplotlib
matplotlib.use("Agg")  # Backend sem interface grÃ¡fica (permite rodar em servidores)
import matplotlib.pyplot as plt
import pandas as pd

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# CONFIGURAÃ‡ÃƒO DE CAMINHOS
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# REPO_ROOT aponta para a raiz do repositÃ³rio (2 nÃ­veis acima deste script).
# Isso permite importar os mÃ³dulos compartilhados de src/utils/.
#
# Estrutura esperada:
#   deep-dive-analyses_v2/          â† REPO_ROOT
#   â”œâ”€â”€ src/utils/excel.py
#   â”œâ”€â”€ data/base_vendas_historica.csv
#   â””â”€â”€ 01_analise_safra/
#       â””â”€â”€ scripts/analise_safra.py  â† vocÃª estÃ¡ aqui

REPO_ROOT = Path(__file__).resolve().parents[2]
sys.path.append(str(REPO_ROOT))

from src.utils.excel import save_portfolio_table

# â”€â”€ Pasta onde os outputs serÃ£o salvos â”€â”€
# Se quiser mudar o destino, altere aqui:
OUTPUT_DIR = REPO_ROOT / "01_analise_safra/outputs"

# â”€â”€ Caminho dos dados de entrada â”€â”€
# Para usar dados reais, troque este caminho:
DATA_PATH = REPO_ROOT / "data/base_vendas_historica.csv"

# â”€â”€ Colunas obrigatÃ³rias na base de dados â”€â”€
# Se sua base tem nomes diferentes, ajuste o mapeamento no passo 1
REQUIRED_COLUMNS = {"cliente_id", "data", "receita"}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# FUNÃ‡Ã•ES AUXILIARES
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def validate_input(df: pd.DataFrame) -> None:
    """
    ValidaÃ§Ãµes de qualidade antes de iniciar a anÃ¡lise.

    EXPLICAÃ‡ÃƒO PARA LEIGOS:
        Antes de construir qualquer anÃ¡lise, um analista sÃªnior
        SEMPRE valida os dados. Ã‰ como um piloto checando os
        instrumentos antes de decolar. Se os dados estÃ£o errados,
        a anÃ¡lise inteira estarÃ¡ errada â€” e ninguÃ©m vai perceber
        atÃ© que uma decisÃ£o ruim seja tomada.
    """
    # 1. Verificar se todas as colunas necessÃ¡rias existem
    missing_cols = REQUIRED_COLUMNS - set(df.columns)
    assert not missing_cols, (
        f"âŒ Colunas ausentes na base: {missing_cols}\n"
        f"   Colunas encontradas: {list(df.columns)}\n"
        f"   SoluÃ§Ã£o: renomeie suas colunas para: {REQUIRED_COLUMNS}"
    )

    # 2. Verificar se nÃ£o hÃ¡ cliente_id nulo (cada transaÃ§Ã£o precisa de dono)
    assert df["cliente_id"].notna().all(), (
        "âŒ Existem transaÃ§Ãµes sem cliente_id. Isso invalida a contagem de coorte."
    )

    # 3. Verificar se receita Ã© sempre positiva (estornos devem ser tratados antes)
    assert df["receita"].gt(0).all(), (
        "âŒ Existem registros com receita â‰¤ 0. Filtre estornos/cancelamentos antes."
    )

    print("   âœ… ValidaÃ§Ã£o de entrada OK")


def build_cohort_matrix(df: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:
    """
    ConstrÃ³i a matriz de coorte: para cada safra (mÃªs de entrada),
    calcula a % de clientes que continuaram comprando em cada mÃªs subsequente.

    EXPLICAÃ‡ÃƒO PARA LEIGOS:
        Imagine que 100 clientes fizeram sua primeira compra em janeiro/2023.
        - Em fevereiro (M1), 72 deles compraram de novo â†’ retenÃ§Ã£o = 72%
        - Em marÃ§o (M2), 58 compraram â†’ retenÃ§Ã£o = 58%
        - Em abril (M3), 51 compraram â†’ retenÃ§Ã£o = 51%

        Fazemos isso para CADA mÃªs de entrada, e colocamos tudo numa tabela.
        Isso Ã© a "matriz de coorte".

    Retorna:
        cohort_counts: DataFrame com colunas [coorte, periodo_idx, clientes_ativos,
                       clientes_base, retencao]
        retention_matrix: DataFrame pivotado (linhas = coorte, colunas = perÃ­odo,
                         valores = % retenÃ§Ã£o)
    """
    # â”€â”€ Passo A: Identificar a safra de cada cliente â”€â”€
    # A safra Ã© o mÃªs da PRIMEIRA compra. Usamos groupby + min para encontrar.
    # Exemplo: se o cliente 123 comprou em 2023-01-15, 2023-02-20, 2023-04-10,
    #          sua safra Ã© "2023-01" (janeiro de 2023).
    first_purchase = (
        df.groupby("cliente_id")["data"]
        .min()                          # Menor data = primeira compra
        .dt.to_period("M")             # Converte para perÃ­odo mensal (2023-01)
        .astype(str)                   # Transforma em string para facilitar joins
        .rename("coorte")
    )

    df = df.join(first_purchase, on="cliente_id")

    # â”€â”€ Passo B: Calcular o "mÃªs de vida" de cada transaÃ§Ã£o â”€â”€
    # periodo_idx = 0 significa "mÃªs da primeira compra" (M0)
    # periodo_idx = 1 significa "1 mÃªs depois da primeira compra" (M1)
    # periodo_idx = 2 significa "2 meses depois" (M2), e assim por diante.
    df["mes_compra"] = df["data"].dt.to_period("M")
    df["coorte_periodo"] = pd.PeriodIndex(df["coorte"], freq="M")
    df["periodo_idx"] = (df["mes_compra"] - df["coorte_periodo"]).apply(lambda x: x.n)

    # â”€â”€ Passo C: Contar clientes Ãºnicos por coorte Ã— perÃ­odo â”€â”€
    # Para cada combinaÃ§Ã£o (safra, mÃªs de vida), contamos quantos clientes
    # distintos fizeram pelo menos uma compra.
    cohort_counts = (
        df.groupby(["coorte", "periodo_idx"])["cliente_id"]
        .nunique()
        .reset_index(name="clientes_ativos")
    )

    # â”€â”€ Passo D: Obter o tamanho base de cada coorte (M0) â”€â”€
    # M0 = quantos clientes entraram naquela safra. Ã‰ o denominador da retenÃ§Ã£o.
    # Exemplo: se 100 clientes entraram em jan/2023, entÃ£o clientes_base = 100.
    base_size = (
        cohort_counts[cohort_counts["periodo_idx"] == 0]
        [["coorte", "clientes_ativos"]]
        .rename(columns={"clientes_ativos": "clientes_base"})
    )

    # ValidaÃ§Ã£o: cada coorte deve aparecer exatamente 1 vez na base
    assert base_size["coorte"].is_unique, (
        "âŒ Duplicidade de coorte na base de referÃªncia. Verifique os dados."
    )

    # â”€â”€ Passo E: Calcular a retenÃ§Ã£o â”€â”€
    # retenÃ§Ã£o = clientes_ativos / clientes_base
    # Exemplo: 72 ativos / 100 na base = 0.72 = 72%
    cohort_counts = cohort_counts.merge(base_size, on="coorte", how="left")
    cohort_counts["retencao"] = (
        cohort_counts["clientes_ativos"] / cohort_counts["clientes_base"]
    ).round(4)

    # ValidaÃ§Ã£o: retenÃ§Ã£o deve estar entre 0% e 100%
    assert cohort_counts["retencao"].between(0, 1).all(), (
        "âŒ RetenÃ§Ã£o fora do range [0, 1]. Verifique duplicidade de clientes."
    )

    # â”€â”€ Passo F: Pivotar para formato de matriz â”€â”€
    # Linhas = coorte (safra), Colunas = perÃ­odo (M0, M1, M2...), Valores = retenÃ§Ã£o
    # PerÃ­odos nÃ£o observados ficam como NaN (nÃ£o como 0!) â€” uma safra recente
    # ainda nÃ£o teve tempo de chegar ao M12, entÃ£o NaN Ã© correto, nÃ£o Ã© churn.
    retention_matrix = (
        cohort_counts
        .pivot(index="coorte", columns="periodo_idx", values="retencao")
        .sort_index()
    )

    return cohort_counts, retention_matrix


def build_summary(
    cohort_counts: pd.DataFrame,
    retention_matrix: pd.DataFrame,
    df: pd.DataFrame,
) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """
    Monta as 3 abas do Excel: resumo, detalhe e parametros.

    EXPLICAÃ‡ÃƒO PARA LEIGOS:
        - Aba "resumo": visÃ£o rÃ¡pida por coorte (quantos entraram, retenÃ§Ã£o M1/M2/M3, receita)
        - Aba "detalhe": a matriz completa de retenÃ§Ã£o para quem quer investigar a fundo
        - Aba "parametros": como os nÃºmeros foram gerados (rastreabilidade)
    """
    # â”€â”€ Resumo: uma linha por coorte com os KPIs principais â”€â”€
    base_size = (
        cohort_counts[cohort_counts["periodo_idx"] == 0]
        [["coorte", "clientes_base"]]
    )
    revenue_by_cohort = df.groupby("coorte", as_index=False)["receita"].sum()
    resumo = base_size.merge(revenue_by_cohort, on="coorte", how="left")

    # Adicionar retenÃ§Ã£o nos marcos M1, M2 e M3 (os mais crÃ­ticos)
    for m in [1, 2, 3]:
        col = (
            cohort_counts[cohort_counts["periodo_idx"] == m]
            [["coorte", "retencao"]]
            .rename(columns={"retencao": f"retencao_m{m}"})
        )
        resumo = resumo.merge(col, on="coorte", how="left")

    resumo["receita"] = resumo["receita"].fillna(0)
    resumo = resumo.sort_values("coorte")

    # â”€â”€ Detalhe: a matriz de retenÃ§Ã£o completa â”€â”€
    detalhe = retention_matrix.reset_index()

    # â”€â”€ Parametros: rastreabilidade da anÃ¡lise â”€â”€
    parametros = pd.DataFrame({
        "parametro": [
            "definicao_coorte",
            "janela_meses",
            "metrica_retencao",
            "data_geracao",
        ],
        "valor": [
            "MÃªs da primeira compra por cliente",
            str(int(df["periodo_idx"].max())),
            "clientes_ativos / clientes_base (M0)",
            datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
        ],
    })

    return resumo, detalhe, parametros


def generate_heatmap(retention_matrix: pd.DataFrame, output_path: Path) -> None:
    """
    Gera o heatmap de retenÃ§Ã£o por coorte.

    COMO LER ESTE GRÃFICO:
        - Cada LINHA Ã© uma safra (mÃªs de entrada dos clientes)
        - Cada COLUNA Ã© o mÃªs de vida (M0 = entrada, M1 = 1 mÃªs depois...)
        - A COR indica a % de retenÃ§Ã£o:
            â†’ Azul escuro = alta retenÃ§Ã£o (bom)
            â†’ Azul claro / branco = baixa retenÃ§Ã£o (alerta)
        - Procure por:
            â†’ Linhas que clareiam rÃ¡pido: safras com churn acelerado
            â†’ Colunas que estabilizam: indica a base "hard core"
    """
    fig, ax = plt.subplots(figsize=(11, 6))

    im = ax.imshow(
        retention_matrix.values,
        aspect="auto",
        cmap="Blues",        # Escala de azul: mais escuro = mais retenÃ§Ã£o
        vmin=0, vmax=1,      # Fixar escala de 0% a 100% para comparabilidade
    )

    # Configurar eixos
    ax.set_xticks(range(retention_matrix.shape[1]))
    ax.set_xticklabels(retention_matrix.columns, fontsize=8)
    ax.set_yticks(range(retention_matrix.shape[0]))
    ax.set_yticklabels(retention_matrix.index, fontsize=8)

    ax.set_title("RetenÃ§Ã£o por Coorte Ã— MÃªs de Vida", fontsize=14, fontweight="bold", pad=15)
    ax.set_xlabel("PerÃ­odo desde a primeira compra (meses)")
    ax.set_ylabel("Coorte (mÃªs de entrada)")

    fig.colorbar(im, ax=ax, label="Taxa de RetenÃ§Ã£o (0 = 0%  |  1 = 100%)")
    fig.tight_layout()
    fig.savefig(output_path, dpi=180)
    plt.close(fig)


def generate_executive_summary(resumo: pd.DataFrame, output_path: Path) -> None:
    """
    Gera o resumo executivo em texto (TXT).

    EXPLICAÃ‡ÃƒO PARA LEIGOS:
        Este arquivo Ã© feito para ser lido em 2 minutos por um diretor
        que quer saber: "o que estÃ¡ acontecendo com nossos clientes?"
        Sem grÃ¡ficos, sem tabelas â€” sÃ³ texto direto ao ponto.
    """
    # Filtrar apenas coortes que jÃ¡ tiveram tempo de chegar ao M1
    # (coortes muito recentes ainda nÃ£o tÃªm dado de retenÃ§Ã£o M1)
    maturadas_m1 = resumo[resumo["retencao_m1"].notna()]

    if maturadas_m1.empty:
        texto = ["âš ï¸ Nenhuma coorte com maturidade suficiente para avaliar retenÃ§Ã£o M1."]
    else:
        # Identificar as 3 melhores e 3 piores coortes em retenÃ§Ã£o M1
        top = maturadas_m1.sort_values("retencao_m1", ascending=False).head(3)["coorte"].tolist()
        low = maturadas_m1.sort_values("retencao_m1", ascending=True).head(3)["coorte"].tolist()

        # Calcular mÃ©dias gerais para contexto
        avg_m1 = maturadas_m1["retencao_m1"].mean()
        avg_m2 = maturadas_m1["retencao_m2"].mean() if "retencao_m2" in maturadas_m1.columns else None
        avg_m3 = maturadas_m1["retencao_m3"].mean() if "retencao_m3" in maturadas_m1.columns else None

        texto = [
            "â•" * 60,
            "RESUMO EXECUTIVO â€” AnÃ¡lise de Safra (Coorte)",
            "â•" * 60,
            "",
            "RESULTADO GERAL:",
            f"  RetenÃ§Ã£o mÃ©dia em M1: {avg_m1:.1%}",
        ]

        if avg_m2 is not None:
            texto.append(f"  RetenÃ§Ã£o mÃ©dia em M2: {avg_m2:.1%}")
        if avg_m3 is not None:
            texto.append(f"  RetenÃ§Ã£o mÃ©dia em M3: {avg_m3:.1%}")

        texto.extend([
            "",
            "COORTES MAIS FORTES (maior retenÃ§Ã£o em M1):",
            f"  {', '.join(top)}",
            "",
            "COORTES MAIS FRACAS (menor retenÃ§Ã£o em M1):",
            f"  {', '.join(low)}",
            "",
            "AÃ‡Ã•ES RECOMENDADAS:",
            "  1. ReforÃ§ar onboarding e CRM no primeiro ciclo pÃ³s-aquisiÃ§Ã£o",
            "     â†’ Os 3 primeiros meses sÃ£o crÃ­ticos: se o cliente sobrevive",
            "       atÃ© M3, a probabilidade de permanÃªncia aumenta significativamente.",
            "  2. Investigar coortes fracas: o que aconteceu no mÃªs de entrada?",
            "     â†’ MudanÃ§a de preÃ§o? Campanha agressiva que trouxe clientes desqualificados?",
            "  3. Ativar campanhas de recompra para coortes com queda acentuada em M1",
            "     â†’ Foco em win-back antes que completem 3 meses de inatividade (Lost).",
            "",
            "PRÃ“XIMOS PASSOS:",
            "  - Segmentar esta anÃ¡lise por canal de venda (PME vs Corporativo vs Grandes Contas)",
            "  - Cruzar com dados de NPS/satisfaÃ§Ã£o para entender motivos de churn",
            "  - Incluir anÃ¡lise de sobrevivÃªncia (Kaplan-Meier) para estimativas com",
            "    intervalo de confianÃ§a",
            "â•" * 60,
        ])

    output_path.write_text("\n".join(texto), encoding="utf-8")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# EXECUÃ‡ÃƒO PRINCIPAL
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main() -> None:
    """
    Pipeline completo da AnÃ¡lise de Safra.

    Executa na ordem:
        1. Carregar e validar dados
        2. Construir matriz de coorte
        3. Montar tabelas de resumo
        4. Gerar heatmap de retenÃ§Ã£o
        5. Gerar resumo executivo
        6. Salvar outputs

    Todos os outputs sÃ£o salvos em: 01_analise_safra/outputs/
    """
    print("\n" + "ğŸ”¬" * 30)
    print("  ANÃLISE DE SAFRA (COORTE) â€” DEEP DIVE #01")
    print("ğŸ”¬" * 30)

    # â”€â”€ PASSO 1: Carregar dados â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ“‚ Passo 1: Carregando dados...")
    df = pd.read_csv(DATA_PATH, parse_dates=["data"])
    print(f"   Registros carregados: {len(df):,}")
    print(f"   PerÃ­odo: {df['data'].min().strftime('%Y-%m')} a {df['data'].max().strftime('%Y-%m')}")
    print(f"   Clientes Ãºnicos: {df['cliente_id'].nunique():,}")

    # â”€â”€ PASSO 2: Validar qualidade dos dados â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ” Passo 2: Validando dados...")
    validate_input(df)

    # â”€â”€ PASSO 3: Construir matriz de coorte â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ“Š Passo 3: Construindo matriz de coorte...")
    cohort_counts, retention_matrix = build_cohort_matrix(df)
    print(f"   Coortes identificadas: {retention_matrix.shape[0]}")
    print(f"   PerÃ­odo mÃ¡ximo de vida: M{retention_matrix.shape[1] - 1}")

    # â”€â”€ PASSO 4: Montar tabelas de resumo â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ“‹ Passo 4: Montando tabelas de resumo...")
    resumo, detalhe, parametros = build_summary(cohort_counts, retention_matrix, df)
    print(f"   Linhas no resumo: {len(resumo)}")

    # â”€â”€ PASSO 5: Gerar outputs â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\nğŸ’¾ Passo 5: Gerando outputs...")
    OUTPUT_DIR.mkdir(parents=True, exist_ok=True)

    # 5a. Excel com 3 abas padronizadas
    save_portfolio_table(
        OUTPUT_DIR,
        "02_tabela_resultados.xlsx",
        resumo=resumo,
        detalhe=detalhe,
        parametros=parametros,
    )
    print(f"   âœ… Excel: {OUTPUT_DIR / '02_tabela_resultados.xlsx'}")

    # 5b. Heatmap de retenÃ§Ã£o
    generate_heatmap(retention_matrix, OUTPUT_DIR / "03_grafico_principal.png")
    print(f"   âœ… GrÃ¡fico: {OUTPUT_DIR / '03_grafico_principal.png'}")

    # 5c. Resumo executivo em texto
    generate_executive_summary(resumo, OUTPUT_DIR / "01_resumo_executivo.txt")
    print(f"   âœ… Resumo: {OUTPUT_DIR / '01_resumo_executivo.txt'}")

    # â”€â”€ RESULTADO FINAL â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    print("\n" + "=" * 60)
    print("âœ… ANÃLISE DE SAFRA CONCLUÃDA!")
    print(f"   Outputs salvos em: {OUTPUT_DIR}")
    print("=" * 60)


if __name__ == "__main__":
    main()
